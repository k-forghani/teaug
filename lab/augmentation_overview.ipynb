{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Swap Augmentation Overview\n",
    "\n",
    "This notebook compares the base, truncated, and truncated+augmented datasets. It provides high-level and detailed views of class balance and text-length distributions, with text summaries alongside each visualization for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from loguru import logger\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_HF_DATASET = \"kforghani/sentipers\"\n",
    "BASE_HF_SPLIT = \"train\"\n",
    "\n",
    "TRUNCATED_CSV = Path(\"data/base/sentipers_train.csv\")\n",
    "AUGMENTED_CSV = Path(\"data/output/augmented_sentipers_train.csv\")\n",
    "\n",
    "CLASS_DEFINITIONS = {\n",
    "    0: {\"name\": \"Very Negative\", \"description\": \"intense dissatisfaction, frustration, or strong criticism\"},\n",
    "    1: {\"name\": \"Negative\", \"description\": \"clear dislike, disappointment, or criticism without extremes\"},\n",
    "    2: {\"name\": \"Neutral\", \"description\": \"factual or balanced tone with no strong positive/negative cues\"},\n",
    "    3: {\"name\": \"Positive\", \"description\": \"clear approval, satisfaction, or praise without extremes\"},\n",
    "    4: {\"name\": \"Very Positive\", \"description\": \"strong enthusiasm, admiration, or high praise\"},\n",
    "}\n",
    "LABEL_NAMES = {key: value[\"name\"] for key, value in CLASS_DEFINITIONS.items()}\n",
    "LABEL_DESCRIPTIONS = {key: value[\"description\"] for key, value in CLASS_DEFINITIONS.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_base_dataset() -> pd.DataFrame:\n",
    "    logger.info(\"Loading base dataset from HuggingFace: {} ({})\", BASE_HF_DATASET, BASE_HF_SPLIT)\n",
    "    hf_ds = load_dataset(BASE_HF_DATASET, split=BASE_HF_SPLIT)\n",
    "    base_df = hf_ds.to_pandas()[[\"text\", \"label\"]]\n",
    "    base_df[\"dataset\"] = \"base\"\n",
    "    base_df[\"is_synthetic\"] = False\n",
    "    return base_df\n",
    "\n",
    "def load_csv_dataset(path: Path, name: str) -> pd.DataFrame:\n",
    "    logger.info(\"Loading dataset from {}\", path)\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[[\"text\", \"label\"] + ([\"is_synthetic\"] if \"is_synthetic\" in df.columns else [])]\n",
    "    df[\"dataset\"] = name\n",
    "    if \"is_synthetic\" not in df.columns:\n",
    "        df[\"is_synthetic\"] = False\n",
    "    df[\"is_synthetic\"] = df[\"is_synthetic\"].astype(bool)\n",
    "    return df\n",
    "\n",
    "base_df = load_base_dataset()\n",
    "truncated_df = load_csv_dataset(TRUNCATED_CSV, \"truncated\")\n",
    "augmented_df = load_csv_dataset(AUGMENTED_CSV, \"augmented\")\n",
    "\n",
    "logger.info(\"Loaded base={} truncated={} augmented={}\", len(base_df), len(truncated_df), len(augmented_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        {\"dataset\": \"base\", \"records\": len(base_df), \"synthetic_ratio\": 0.0},\n",
    "        {\"dataset\": \"truncated\", \"records\": len(truncated_df), \"synthetic_ratio\": 0.0},\n",
    "        {\"dataset\": \"augmented\", \"records\": len(augmented_df),\n",
    "         \"synthetic_ratio\": augmented_df[\"is_synthetic\"].mean()},\n",
    "    ]\n",
    ")\n",
    "summary[\"synthetic_ratio\"] = (summary[\"synthetic_ratio\"] * 100).round(2)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution (High-Level)\n",
    "This compares label counts across base, truncated, and augmented datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_label_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"label_name\"] = df[\"label\"].map(LABEL_NAMES)\n",
    "    df[\"label_description\"] = df[\"label\"].map(LABEL_DESCRIPTIONS)\n",
    "    return df\n",
    "\n",
    "def class_distribution(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    counts = df.groupby([\"dataset\", \"label\"]).size().reset_index(name=\"count\")\n",
    "    totals = counts.groupby(\"dataset\")[\"count\"].transform(\"sum\")\n",
    "    counts[\"percent\"] = (counts[\"count\"] / totals * 100).round(1)\n",
    "    counts[\"label_name\"] = counts[\"label\"].map(LABEL_NAMES)\n",
    "    counts[\"label_description\"] = counts[\"label\"].map(LABEL_DESCRIPTIONS)\n",
    "    return counts\n",
    "\n",
    "combined_df = pd.concat([base_df, truncated_df, augmented_df], ignore_index=True)\n",
    "combined_df = add_label_name(combined_df)\n",
    "class_counts = class_distribution(combined_df)\n",
    "class_counts.sort_values([\"dataset\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger.info(\"Class distribution summary (counts, %%) for each dataset:\\n{}\", class_counts)\n",
    "\n",
    "sns.barplot(data=class_counts, x=\"label_name\", y=\"count\", hue=\"dataset\")\n",
    "plt.title(\"Class Distribution by Dataset\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Dataset: Base vs Synthetic Balance\n",
    "This breaks down class counts inside the augmented dataset by origin (base vs synthetic).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "augmented_only = augmented_df.copy()\n",
    "augmented_only[\"label_name\"] = augmented_only[\"label\"].map(LABEL_NAMES)\n",
    "\n",
    "aug_split = (\n",
    "    augmented_only.groupby([\"label_name\", \"is_synthetic\"]).size().reset_index(name=\"count\")\n",
    ")\n",
    "aug_split[\"origin\"] = np.where(aug_split[\"is_synthetic\"], \"synthetic\", \"base\")\n",
    "aug_split\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger.info(\"Augmented dataset origin split:\\n{}\", aug_split)\n",
    "\n",
    "pivot = aug_split.pivot(index=\"label_name\", columns=\"origin\", values=\"count\").fillna(0)\n",
    "pivot.plot(kind=\"bar\", stacked=True)\n",
    "plt.title(\"Augmented Dataset: Base vs Synthetic Counts\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length Distributions (High-Level)\n",
    "We compare character and word length distributions across datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_length_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"char_len\"] = df[\"text\"].str.len()\n",
    "    df[\"word_len\"] = df[\"text\"].str.split().str.len()\n",
    "    return df\n",
    "\n",
    "combined_len_df = add_length_features(combined_df)\n",
    "\n",
    "length_summary = (\n",
    "    combined_len_df.groupby(\"dataset\")[[\"char_len\", \"word_len\"]]\n",
    "    .agg([\"mean\", \"median\", lambda s: np.percentile(s, 95)])\n",
    ")\n",
    "length_summary.columns = [\"_\".join(map(str, col)).replace(\"<lambda_0>\", \"p95\") for col in length_summary.columns]\n",
    "length_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger.info(\"Text length summary (mean/median/p95):\\n{}\", length_summary)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.histplot(data=combined_len_df, x=\"char_len\", hue=\"dataset\", bins=40, ax=axes[0])\n",
    "axes[0].set_title(\"Character Length Distribution\")\n",
    "axes[0].set_xlabel(\"Characters\")\n",
    "\n",
    "sns.histplot(data=combined_len_df, x=\"word_len\", hue=\"dataset\", bins=40, ax=axes[1])\n",
    "axes[1].set_title(\"Word Length Distribution\")\n",
    "axes[1].set_xlabel(\"Words\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic vs Base Text Length (Augmented Dataset)\n",
    "This highlights whether synthetic samples differ in length from base records.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug_len_df = add_length_features(augmented_df)\n",
    "aug_len_df[\"origin\"] = np.where(aug_len_df[\"is_synthetic\"], \"synthetic\", \"base\")\n",
    "\n",
    "origin_summary = (\n",
    "    aug_len_df.groupby(\"origin\")[[\"char_len\", \"word_len\"]]\n",
    "    .agg([\"mean\", \"median\", lambda s: np.percentile(s, 95)])\n",
    ")\n",
    "origin_summary.columns = [\"_\".join(map(str, col)).replace(\"<lambda_0>\", \"p95\") for col in origin_summary.columns]\n",
    "origin_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger.info(\"Synthetic vs base length summary:\\n{}\", origin_summary)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.boxplot(data=aug_len_df, x=\"origin\", y=\"char_len\", ax=axes[0])\n",
    "axes[0].set_title(\"Character Length: Base vs Synthetic\")\n",
    "\n",
    "sns.boxplot(data=aug_len_df, x=\"origin\", y=\"word_len\", ax=axes[1])\n",
    "axes[1].set_title(\"Word Length: Base vs Synthetic\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length by Class (Base vs Synthetic)\n",
    "This compares per-class length distributions between base and synthetic records.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug_len_df[\"label_name\"] = aug_len_df[\"label\"].map(LABEL_NAMES)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.boxplot(data=aug_len_df, x=\"label_name\", y=\"char_len\", hue=\"origin\", ax=axes[0])\n",
    "axes[0].set_title(\"Character Length by Class\")\n",
    "axes[0].set_xlabel(\"Class\")\n",
    "axes[0].set_ylabel(\"Characters\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "sns.boxplot(data=aug_len_df, x=\"label_name\", y=\"word_len\", hue=\"origin\", ax=axes[1])\n",
    "axes[1].set_title(\"Word Length by Class\")\n",
    "axes[1].set_xlabel(\"Class\")\n",
    "axes[1].set_ylabel(\"Words\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Reporting\n",
    "- Use the class distribution table and chart to highlight balance changes after augmentation.\n",
    "- Use length summaries to describe how synthetic data compares in length to base data.\n",
    "- Use per-class length boxplots to call out any label-specific artifacts introduced by augmentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
